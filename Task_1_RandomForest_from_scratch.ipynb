{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "name": "Task 1 - RandomForest_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5A6n7jvYxPC"
      },
      "source": [
        "#Vehicle silhouettes\n",
        "\n",
        "##Objective\n",
        "To classify a given silhouette as one of four types of vehicle, \tusing a set of features extracted from the silhouette. The \tvehicle may be viewed from one of many different angles.   \n",
        "\n",
        "##Description\n",
        "\n",
        "###The features were extracted from the silhouettes by the HIPS\n",
        "(Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale independent features utilising\tboth classical moments based measures such as scaled variance,\tskewness and kurtosis about the major/minor axes and heuristic\tmeasures such as hollows, circularity, rectangularity and\tcompactness. Four \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.\tThis particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.\n",
        "\t\n",
        "##Source: https://www.kaggle.com/rajansharma780/vehicle\n",
        "\n",
        "## ATTRIBUTES\n",
        "1.\tcompactness\tfloat\taverage perimeter**2/area\n",
        "2.\tcircularity\tfloat\taverage radius**2/area\n",
        "3.\tdistance_circularity\tfloat\tarea/(av.distance from border)**2\n",
        "4.\tradius_ratio\tfloat\t(max.rad-min.rad)/av.radius\n",
        "5.\tpr_axis_aspect_ratio\tfloat\t(minor axis)/(major axis)\n",
        "6.\tmax_length_aspect_ratio\tfloat\t(length perp. max length)/(max length)\n",
        "7.\tscatter_ratio\tfloat\t(inertia about minor axis)/(inertia about major axis)\n",
        "8.\telongatedness\tfloat\tarea/(shrink width)**2\n",
        "9.\tpr_axis_rectangularity\tfloat\tarea/(pr.axis length*pr.axis width)\n",
        "10.\tmax_length_rectangularity\tfloat\tarea/(max.length*length perp. to this)\n",
        "11.\tscaled_variance_major_axis\tfloat\t(2nd order moment about minor axis)/area\n",
        "12.\tscaled_variance_minor_axis\tfloat\t(2nd order moment about major axis)/area\n",
        "13.\tscaled_radius_gyration\tfloat\t(mavar+mivar)/area\n",
        "14.\tskewness_major_axis\tfloat\t(3rd order moment about major axis)/sigma_min**3\n",
        "15.\tskewness_minor_axis\tfloat\t(3rd order moment about minor axis)/sigma_maj**3\n",
        "16.\tkurtosis_minor_axis\tfloat\t(4th order moment about major axis)/sigma_min**4\n",
        "17.\tkurtosis_major_axis\tfloat\t(4th order moment about minor axis)/sigma_maj**4\n",
        "18.\thollows_ratio\tfloat\t(area of hollows)/(area of bounding polygon)\n",
        "\n",
        "##Target variable\n",
        "19.\tvehicle_class\tstring\tPredictor Class. Values: Opel, Saab, Bus, Van\t\n",
        "\n",
        "#Tasks:\n",
        "1.\tObtain the multi-class dataset from the given link\n",
        "2.\tLoad the dataset\n",
        "3.\tApply pre-processing techniques: Encoding, Scaling\n",
        "4.\tDivide the dataset into training (70%) and testing (30%)\n",
        "5.\tBuild your own random forest model from scratch (using invidual decision tree model from sklearn)\n",
        "6.\tTrain the random forest model\n",
        "7.\tTest the random forest model\n",
        "8.\tTrain and test the random forest model using sklearn.\n",
        "9.\tCompare the performance of both the models\n",
        "\n",
        "##Useful links:\n",
        "https://machinelearningmastery.com/implement-random-forest-scratch-python/\n",
        "\n",
        "https://towardsdatascience.com/random-forests-and-decision-trees-from-scratch-in-python-3e4fa5ae4249\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/12/building-a-random-forest-from-scratch-understanding-real-world-data-products-ml-for-programmers-part-3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FoSpD3QDP4"
      },
      "source": [
        "# Part 1: Random Forest from scratch\n",
        "\n",
        "Random forests are an ensemble learning method for classification and regression that operate by constructing multiple decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q0F2HVFPl0R"
      },
      "source": [
        "# Load the libraries\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VACehGfwPoAg"
      },
      "source": [
        "# Load the dataset \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47gOYRhPqKF"
      },
      "source": [
        "# Preprocessing\n",
        "# Encoding categorical variables (if any)\n",
        "# Feature Scaling\n",
        "# Filling missing values (if any)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJGz-VZP2R9"
      },
      "source": [
        "# Divide the dataset to training and testing set\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu9YAA53YxPG"
      },
      "source": [
        "# Randomly choose the features from training set and build decision tree\n",
        "# Randomness in the features will help us to achieve different DTrees every time\n",
        "# You can keep minimum number of random features every time so that trees will have sufficient features\n",
        "# Note: You can use builtin function for DT training using Sklearn\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22bKlgbZYxPQ"
      },
      "source": [
        "# Train N number of decision trees using random feature selection strategy\n",
        "# Number of trees N can be user input\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBsseNEYxPX"
      },
      "source": [
        "# Apply different voting mechanisms such as \n",
        "# max voting/average voting/weighted average voting (using accuracy as weightage)\n",
        "# Perform the ensembling for the training set.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEQjBB3RBpM"
      },
      "source": [
        "# Apply invidual trees trained on the testingset\n",
        "# Note: You should've saved the feature sets used for training invidual trees,\n",
        "# so that same features can be chosen in testing set\n",
        "\n",
        "# Get predictions on testing set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qQ84BJRcNP"
      },
      "source": [
        "# Evaluate the results using accuracy, precision, recall and f-measure\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_-xfr-CRoDa"
      },
      "source": [
        "# Compare different voting mechanisms and their accuracies\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2UXYktmRryu"
      },
      "source": [
        "# Compare the Random forest models with different number of trees N\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grD0B0qRwOI"
      },
      "source": [
        "# Compare different values for minimum number of features needed for individual trees\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGVYWKUcRnhA"
      },
      "source": [
        "## Part 2: Random Forest using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vJ02XgwRm-O"
      },
      "source": [
        "# Use the preprocessed dataset here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHEEc7BrSDG0"
      },
      "source": [
        "# Train the Random Forest Model using builtin Sklearn Dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-YJEeqPSIk1"
      },
      "source": [
        "# Test the model with testing set and print the accuracy, precision, recall and f-measure\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlwe8gonSVFd"
      },
      "source": [
        "# Play with parameters such as\n",
        "# number of decision trees\n",
        "# Criterion for splitting\n",
        "# Max depth\n",
        "# Minimum samples per split and leaf"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}